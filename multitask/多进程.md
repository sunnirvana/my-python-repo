
# 多进程相关
- os.fork
- multiprocessing Process
- multiprocessing Pool
- subprocess
- multiprocessing Queue, Pipes

在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。

## os.fork
使用fork创建多进程，返回2次。0为子进程，非0为父进程
从调用fork()开始就已经是多进程
os.fork()只能在Unix-like的操作系统上运行，Windows下没有


```python
# 例子，调用fork
import os

pid = os.fork()

print('Process (%s) start...' % os.getpid())

if pid == 0:
    print('I am the child process (%d), created by the process (%d)' % (os.getpid(), os.getppid()))
else:
    print('I am the parent process (%d), spawn a child process (%d)' % (os.getpid(), pid))
```

    Process (21132) start...
    I am the parent process (21132), spawn a child process (24016)
    Process (24016) start...
    I am the child process (24016), created by the process (21132)


## multiprocessing
跨平台的多进程。


```python
# 例子，启动子进程
from multiprocessing import Process
import os

def run_proc(name):
    print('Run child process %s (%s)' % (name, os.getpid()))
    
def main():
    print('Parent process %s.' % os.getpid())
    p = Process(target=run_proc, args=('test', ))
    print('Child process will start.')
    # 子进程开启
    p.start()
    # join方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步
    p.join()
    print('Child process ends.')
    
main()
```

    Parent process 25599.
    Child process will start.
    Run child process test (45583)
    Child process ends.


# Pool
启动多个子进程


```python
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print('Run task %s (%s)...' % (name, os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %.2f seconds. ' % (name, (end - start)))

def main():
    print('Parent process %s.' % os.getpid())
    # Pool的默认大小是CPU的核数
    p = Pool(4)
    for i in range(5):
        p.apply_async(long_time_task, args=('task %d' % i, ))
    print('Waiting for all subprocesses done...')
    
    # 调用join之前必须调用close, 调用close后就不能继续添加process了
    p.close()
    p.join()
    
    print('All subprocesses done.')
    
main()
        
```

    Parent process 25599.
    Run task task 0 (48521)...
    Run task task 2 (48523)...
    Run task task 3 (48524)...
    Run task task 1 (48522)...
    Waiting for all subprocesses done...
    Task task 3 runs 1.09 seconds. 
    Run task task 4 (48524)...
    Task task 0 runs 1.55 seconds. 
    Task task 2 runs 2.03 seconds. 
    Task task 1 runs 2.30 seconds. 
    Task task 4 runs 2.24 seconds. 
    All subprocesses done.


从输出结果看，Task4是等到上面4个任务(一共5个)中的一个完成后，才运行的。

## 子进程

subprocess模块可以非常方便地启动一个子进程，然后控制其输入和输出


```python
import subprocess

print('$ nslookup www.python.org')
r = subprocess.call(('nslookup', 'www.python.org'))
print('Exit code:', r)
```

    $ nslookup www.python.org
    Exit code: 0



```python
import subprocess

print('$ nslookup')
p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
output, err = p.communicate(b'set q=mx\npython.org\nexit\n')
print(output.decode('utf-8'))
print(err.decode('utf-8'))
print('Exit code:', p.returncode)
```

    $ nslookup
    Server:		10.8.8.8
    Address:	10.8.8.8#53
    
    Non-authoritative answer:
    python.org	mail exchanger = 50 mail.python.org.
    
    Authoritative answers can be found from:
    
    
    
    Exit code: 0


原来下面这种方法就可以简单获取output和err


```python
import subprocess

print('$ ls -l')
p = subprocess.Popen(['ls', '-l'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
output, err = p.communicate(b'')
print(output.decode('utf-8'))
print(err.decode('utf-8'))
print('Exit code:', p.returncode)
```

    $ ls -l
    total 40
    -rw-r--r--  1 sunyubo  staff   252 11 26 14:19 do_folk.py
    -rw-r--r--  1 sunyubo  staff     0 12  1 17:46 err.txt
    -rw-r--r--  1 sunyubo  staff   244 12  1 17:46 out.txt
    -rw-r--r--  1 sunyubo  staff  8652 12  1 17:50 多进程.ipynb
    
    
    Exit code: 0


尝试获取执行命令的stdout和stderr
- ByteIO 失败，因为没有fileno方法
- File 成功，将结果写到两个文件中


```python
import subprocess
from io import BytesIO
import pathlib
import time

print('$ ls -l')

out = open('out.txt', 'wb')
err = open('err.txt', 'wb')

p = subprocess.Popen(['ls', '-l'], stdout=out, stderr=err)
print('Done with code', p.returncode)

print(out.tell())
out.flush()
print(out.tell())
# err.flush()
# out.close()
print(out.tell())
# err.close()

time.sleep(1)
print(out.tell())

for file in ['out.txt', 'err.txt']:
    print('Reading %s' % (file, ))
    with open(file, 'rb') as f:
        c = f.read()
        print(c.decode('utf-8'))
```

    $ ls -l
    Done with code None
    0
    0
    0
    244
    Reading out.txt
    total 32
    -rw-r--r--  1 sunyubo  staff    252 11 26 14:19 do_folk.py
    -rw-r--r--  1 sunyubo  staff      0 12  1 17:46 err.txt
    -rw-r--r--  1 sunyubo  staff      0 12  1 17:46 out.txt
    -rw-r--r--  1 sunyubo  staff  10537 12  1 17:44 多进程.ipynb
    
    Reading err.txt
    


## 进程间通讯


```python
from multiprocessing import Process, Queue
import os, time, random

# 写数据进程
def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to quese...' % value)
        q.put(value)
        time.sleep(random.random() * 3)
    
# 读数据进程
def read(q):
    print('Process to read: %s' % os.getpid())
    while True:
        value = q.get(True)
        print('Get %s from queue.' % value)
        
def main():
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    
    # 启动写进程
    pw.start()
    
    # 启动读进程
    pr.start()
    
    # 等待写进程结束
    pw.join()
    
    # 强行终止读进程
    pr.terminate()

main()
```

    Process to write: 63021
    Put A to quese...
    Process to read: 63022
    Get A from queue.
    Put B to quese...
    Get B from queue.
    Put C to quese...
    Get C from queue.

